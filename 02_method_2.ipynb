{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ac4ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-28 22:42:11.733647: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-28 22:42:12.453695: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-28 22:42:13.877886: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/include:/usr/local/cuda-11.0/lib64:\n",
      "2023-09-28 22:42:13.878024: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/include:/usr/local/cuda-11.0/lib64:\n",
      "2023-09-28 22:42:13.878033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from utils.alloys import alloy_to_1d_tensor, make_params_df, get_elements_and_compositions, element_to_index\n",
    "from utils.constants import alloy_max_len, n_elements\n",
    "from utils.ml import *\n",
    "from utils.dataframes import dfs_tabs\n",
    "from utils.rnn_predictor import LSTMClassifier, LSTMClassifierBidirectional, save_model_and_see_stats, save_predictions\n",
    "from utils.ml import run_all_regressors, run_all_regressors_with_transformers\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e558c076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1269, 3)\n",
      "Testing set shape: (318, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train_final_df.csv\")\n",
    "df_test = pd.read_csv(\"test_final_df.csv\")\n",
    "\n",
    "print(\"Training set shape:\", df_train.shape)\n",
    "print(\"Testing set shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2275776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.0\n"
     ]
    }
   ],
   "source": [
    "# constants\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ideally a max factor is from the training dataset\n",
    "max_factor = max(df_train[\"actual_d_max\"])\n",
    "print(max_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c77724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the input and output data for the model\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "elements_vector_df = pd.read_csv(\"utils/elements_wvmodel_2016_12-15-20.csv\")\n",
    "\n",
    "def alloy_to_vectorized_tensor(alloy_str, alloy_max_len = alloy_max_len):\n",
    "    tensor = torch.zeros(118, 200)\n",
    "    elements, compositions = get_elements_and_compositions(alloy_str)\n",
    "    i = 0\n",
    "    for idx in range(0, len(elements) + len(compositions), 2):\n",
    "        tensor[element_to_index(elements[i]), :] = torch.tensor(np.array(elements_vector_df[elements[i]])) * compositions[i]\n",
    "        i += 1\n",
    "    return tensor\n",
    "\n",
    "for i in range(df_train.shape[0]):\n",
    "    X_train.append(alloy_to_vectorized_tensor(df_train.loc[i, \"bmg_alloy\"]))\n",
    "    y_train.append(df_train.loc[i, \"actual_d_max\"] / max_factor)\n",
    "\n",
    "X_train = torch.stack(X_train)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "for i in range(df_test.shape[0]):\n",
    "    X_test.append(alloy_to_vectorized_tensor(df_test.loc[i, \"bmg_alloy\"]))\n",
    "    y_test.append(df_test.loc[i, \"actual_d_max\"] / max_factor)\n",
    "    \n",
    "# max_factor we selected is fine\n",
    "X_test = torch.stack(X_test)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "print(\"X_train (shape and min-max):\", X_train.shape, min(X_train.view(-1, 1)), max(X_train.view(-1, 1)),\n",
    "      \"y_train (shape and min-max):\", y_train.shape, min(y_train.view(-1, 1)), max(y_train.view(-1, 1)))\n",
    "\n",
    "print(\"X_test (shape and min-max):\", X_test.shape, min(X_test.view(-1, 1)), max(X_test.view(-1, 1)),\n",
    "      \"y_test (shape and min-max):\", y_test.shape, min(y_test.view(-1, 1)), max(y_test.view(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646d7081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
