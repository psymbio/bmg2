{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b877b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-17 15:45:46.018985: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-17 15:45:46.562047: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-09-17 15:45:47.672972: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/include:/usr/local/cuda-11.0/lib64:\n",
      "2023-09-17 15:45:47.673409: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.0/include:/usr/local/cuda-11.0/lib64:\n",
      "2023-09-17 15:45:47.673426: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from utils.alloys import alloy_to_1d_tensor, get_elements_and_compositions, element_to_index\n",
    "from utils.constants import alloy_max_len, n_elements\n",
    "from utils.ml import *\n",
    "from utils.dataframes import dfs_tabs\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa195676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1269, 3)\n",
      "Testing set shape: (318, 3)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train_final_df.csv\")\n",
    "df_test = pd.read_csv(\"test_final_df.csv\")\n",
    "\n",
    "# Print the shape of the training and testing sets to check the split sizes\n",
    "print(\"Training set shape:\", df_train.shape)\n",
    "print(\"Testing set shape:\", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39ac64b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.0\n"
     ]
    }
   ],
   "source": [
    "# constants\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ideally a max factor is from the training dataset\n",
    "max_factor = max(df_train[\"actual_d_max\"])\n",
    "print(max_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a10af4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1269, 20, 200]) torch.float32 torch.Size([1269]) 0.0 1.0\n",
      "torch.Size([318, 20, 200]) 0.0 0.8571428656578064\n"
     ]
    }
   ],
   "source": [
    "# creating the input and output data for the model\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "elements_vector_df = pd.read_csv(\"utils/elements_wvmodel_2016_12-15-20.csv\")\n",
    "\n",
    "def alloy_to_vectorized_tensor(alloy_str, alloy_max_len = alloy_max_len):\n",
    "    tensor = torch.zeros(alloy_max_len, 200)\n",
    "    elements, compositions = get_elements_and_compositions(alloy_str)\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for idx in range(0, len(elements) + len(compositions), 2):\n",
    "        tensor[j, :] = torch.tensor(np.array(elements_vector_df[elements[i]]))\n",
    "        tensor[j, int(compositions[i])] = 1\n",
    "        i += 1\n",
    "        j += 2\n",
    "    return tensor\n",
    "\n",
    "\n",
    "for i in range(df_train.shape[0]):\n",
    "    X_train.append(alloy_to_vectorized_tensor(df_train.loc[i, \"bmg_alloy\"]))\n",
    "    y_train.append(df_train.loc[i, \"actual_d_max\"] / max_factor)\n",
    "    \n",
    "X_train = torch.stack(X_train)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "print(X_train.shape, X_train.dtype, y_train.shape, min(y_train).item(), max(y_train).item())\n",
    "\n",
    "for i in range(df_test.shape[0]):\n",
    "    X_test.append(alloy_to_vectorized_tensor(df_test.loc[i, \"bmg_alloy\"]))\n",
    "    y_test.append(df_test.loc[i, \"actual_d_max\"] / max_factor)\n",
    "    \n",
    "X_test = torch.stack(X_test)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "print(X_test.shape, min(y_test).item(), max(y_test).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7032c90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 8.0976e-08,  2.1794e-08,  2.0667e-09,  ..., -1.3152e-08,\n",
      "          9.9200e-08,  1.5030e-09],\n",
      "        [        nan,         nan,         nan,  ...,         nan,\n",
      "                 nan,         nan],\n",
      "        [ 8.5673e-08, -7.5152e-10, -2.6867e-08,  ...,  8.9806e-08,\n",
      "         -8.2667e-08, -2.2545e-08],\n",
      "        ...,\n",
      "        [        nan,         nan,         nan,  ...,         nan,\n",
      "                 nan,         nan],\n",
      "        [        nan,         nan,         nan,  ...,         nan,\n",
      "                 nan,         nan],\n",
      "        [        nan,         nan,         nan,  ...,         nan,\n",
      "                 nan,         nan]]) tensor([[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
      "        [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "        ...,\n",
      "        [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
      "        [   nan,    nan,    nan,  ...,    nan,    nan,    nan],\n",
      "        [   nan,    nan,    nan,  ...,    nan,    nan,    nan]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming X_train and X_test are Python lists of data\n",
    "# Convert them to PyTorch tensors\n",
    "X_train = torch.tensor(X_train)\n",
    "X_test = torch.tensor(X_test)\n",
    "\n",
    "# Calculate mean and standard deviation from the training data along axis 0\n",
    "mean = torch.mean(X_train, dim=0)\n",
    "std = torch.std(X_train, dim=0)\n",
    "\n",
    "epsilon = 1e-8  # You can adjust this value if needed\n",
    "std = std + epsilon\n",
    "mean = mean + epsilon\n",
    "print(mean, std)\n",
    "\n",
    "# Normalize the data\n",
    "normalized_X_train = (X_train - mean) / std\n",
    "normalized_X_test = (X_test - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb2e6c97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ab78f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(X_train)\n\u001b[0;32m---> 46\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/loss.py:612\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 612\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/functional.py:3065\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3062\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3063\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3065\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMClassifier, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Take the output of the last time step\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "# Define the model parameters\n",
    "input_size = 200\n",
    "hidden_size = 128\n",
    "num_layers = 3\n",
    "output_size = 1\n",
    "\n",
    "# Create the model\n",
    "model = LSTMClassifier(input_size, hidden_size, num_layers, output_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "# criterion = nn.BCELoss()  # R2 Score: 0.69\n",
    "# criterion = nn.MSELoss() # R2 Score: 0.0146\n",
    "# criterion = nn.KLDivLoss()\n",
    "criterion = nn.BCELoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "# Convert your data to PyTorch tensors\n",
    "X_train = torch.tensor(normalized_X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "y_train = y_train.view(-1, 1)\n",
    "# Training loop\n",
    "num_epochs = 5000\n",
    "print_every = 100\n",
    "plot_loss = []\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % print_every == 0:\n",
    "        print(f\"Epoch {epoch}/{num_epochs}, Loss: {loss.item():.4f}\")\n",
    "    plot_loss.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f220f859",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(plot_loss)), plot_loss)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"rnn_trainset_trained_method_3.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4c5fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted_labels = model(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44df1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(np.array(y_test)*max_factor, np.array(predicted_labels).reshape(-1)*max_factor)\n",
    "print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39be29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x=np.array(y_test)*max_factor, y=np.array(predicted_labels).reshape(-1)*max_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e157a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rnn_train_output = []\n",
    "for i in range(df_train.shape[0]):\n",
    "    alloy_tensor = alloy_to_vectorized_tensor(df_train.loc[i, \"bmg_alloy\"])\n",
    "    output = model(alloy_tensor.unsqueeze(0))\n",
    "    all_rnn_train_output.append(output.squeeze().item() * max_factor)\n",
    "\n",
    "all_rnn_test_output = []\n",
    "for i in range(df_test.shape[0]):\n",
    "    alloy_tensor =  alloy_to_vectorized_tensor(df_test.loc[i, \"bmg_alloy\"])\n",
    "    output = model(alloy_tensor.unsqueeze(0))\n",
    "    all_rnn_test_output.append(output.squeeze().item() * max_factor)\n",
    "    \n",
    "new_train = df_train\n",
    "new_test = df_test\n",
    "\n",
    "\n",
    "new_train[\"rnn_encoding\"] = all_rnn_train_output\n",
    "new_test[\"rnn_encoding\"] = all_rnn_test_output\n",
    "    \n",
    "dfs = [new_train, new_test]\n",
    "sheets = [\"train\", \"test\"]\n",
    "dfs_tabs(dfs, sheets, 'dataset_rnn.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5411504c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(\"dataset_rnn.xlsx\", sheet_name=\"train\")\n",
    "df_test = pd.read_excel(\"dataset_rnn.xlsx\", sheet_name=\"test\")\n",
    "display(df_train)\n",
    "display(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69abb4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(\"dataset_rnn.xlsx\", index_col=0, sheet_name=\"train\")\n",
    "df_test = pd.read_excel(\"dataset_rnn.xlsx\", index_col=0, sheet_name=\"test\")\n",
    "# df_test = df_test.drop([\"predicted_d_max\"], axis=1)\n",
    "df_train = df_train.drop([\"paper_sno\"], axis=1)\n",
    "df_test = df_test.drop([\"paper_sno\"], axis=1)\n",
    "X_train, y_train = df_train.loc[:, df_train.columns != \"actual_d_max\"], pd.DataFrame(df_train[\"actual_d_max\"])\n",
    "X_test, y_test = df_test.loc[:, df_test.columns != \"actual_d_max\"], pd.DataFrame(df_test[\"actual_d_max\"])\n",
    "\n",
    "R2 = []\n",
    "ADJR2 = []\n",
    "RMSE = []\n",
    "names = []\n",
    "TIME = []\n",
    "\n",
    "for name, model in tqdm(REGRESSORS):\n",
    "    start = time.time()\n",
    "    pipe = Pipeline(steps=[\n",
    "                        (\"classifier\", model()),\n",
    "                    ]\n",
    "                )\n",
    "    try:\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        r_squared = r2_score(y_test, y_pred)\n",
    "        print(name, r_squared)\n",
    "        adj_rsquared = adjusted_rsquared(\n",
    "            r_squared, X_test.shape[0], X_test.shape[1]\n",
    "        )\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        names.append(name)\n",
    "        R2.append(r_squared)\n",
    "        ADJR2.append(adj_rsquared)\n",
    "        RMSE.append(rmse)\n",
    "        TIME.append(time.time() - start)\n",
    "    except Exception as exception:\n",
    "        print(name + \" model failed to execute\")\n",
    "        print(exception)\n",
    "    scores = {\n",
    "                \"Model\": names,\n",
    "                \"Adjusted R-Squared\": ADJR2,\n",
    "                \"R-Squared\": R2,\n",
    "                \"RMSE\": RMSE,\n",
    "                \"Time Taken\": TIME,\n",
    "            }\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores = scores.sort_values(by = \"Adjusted R-Squared\", ascending = False).set_index(\"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fb937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0961d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_excel(\"dataset_rnn.xlsx\", index_col=0, sheet_name=\"train\")\n",
    "df_test = pd.read_excel(\"dataset_rnn.xlsx\", index_col=0, sheet_name=\"test\")\n",
    "# df_test = df_test.drop([\"predicted_d_max\"], axis=1)\n",
    "df_train = df_train.drop([\"paper_sno\"], axis=1)\n",
    "df_test = df_test.drop([\"paper_sno\"], axis=1)\n",
    "X_train, y_train = df_train.loc[:, df_train.columns != \"actual_d_max\"], pd.DataFrame(df_train[\"actual_d_max\"])\n",
    "X_test, y_test = df_test.loc[:, df_test.columns != \"actual_d_max\"], pd.DataFrame(df_test[\"actual_d_max\"])\n",
    "\n",
    "R2 = []\n",
    "ADJR2 = []\n",
    "RMSE = []\n",
    "names = []\n",
    "TIME = []\n",
    "\n",
    "for transformer_method_name, transformer_method in tqdm(TRANSFOMER_METHODS):\n",
    "    for name, model in tqdm(REGRESSORS):\n",
    "        start = time.time()\n",
    "        X_transformer = transformer_method()\n",
    "        y_transformer = transformer_method()\n",
    "        transformed_X_train = pd.DataFrame(X_transformer.fit_transform(X_train), columns = X_train.columns)\n",
    "        transformed_X_test = pd.DataFrame(X_transformer.transform(X_test), columns = X_test.columns)\n",
    "\n",
    "        transformed_y_train = pd.DataFrame(y_transformer.fit_transform(y_train), columns = y_train.columns)\n",
    "        transformed_y_test = pd.DataFrame(y_transformer.transform(y_test), columns = y_test.columns)\n",
    "        pipe = Pipeline(steps=[\n",
    "                            (\"classifier\", model()),\n",
    "                        ]\n",
    "                    )\n",
    "        try:\n",
    "            pipe.fit(transformed_X_train, transformed_y_train)\n",
    "            transformed_y_pred = pipe.predict(transformed_X_test)\n",
    "            r_squared = r2_score(transformed_y_test, transformed_y_pred)\n",
    "            adj_rsquared = adjusted_rsquared(\n",
    "                r_squared, transformed_X_test.shape[0], transformed_X_test.shape[1]\n",
    "            )\n",
    "            rmse = np.sqrt(mean_squared_error(transformed_y_test, transformed_y_pred))\n",
    "            names.append(name + \" (\" + transformer_method_name + \")\")\n",
    "            print(name + \" (\" + transformer_method_name + \")\", r_squared)\n",
    "            R2.append(r_squared)\n",
    "            ADJR2.append(adj_rsquared)\n",
    "            RMSE.append(rmse)\n",
    "            TIME.append(time.time() - start)\n",
    "        except Exception as exception:\n",
    "            print(name + \" (\" + transformer_method_name + \")\" + \" model failed to execute\")\n",
    "            print(exception)\n",
    "        scores = {\n",
    "                    \"Model\": names,\n",
    "                    \"Adjusted R-Squared\": ADJR2,\n",
    "                    \"R-Squared\": R2,\n",
    "                    \"RMSE\": RMSE,\n",
    "                    \"Time Taken\": TIME,\n",
    "                }\n",
    "        scores = pd.DataFrame(scores)\n",
    "        scores = scores.sort_values(by = \"Adjusted R-Squared\", ascending = False).set_index(\"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260045bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(scores[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32458d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
